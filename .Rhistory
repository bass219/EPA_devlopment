library("RColorBrewer")
library(xgboost)
Sys.setenv(VROOM_CONNECTION_SIZE = 131072 * 10)
# Load the 2024-2025 NBA game data
game_logs_2025 <- game_logs(seasons = 2025)
install.packages("gbm.auto")
install.packages("gbm2sas")
install.packages("lime")
install.packages("gbmt")
install.packages("h2o", repos = "https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type = "source")
install.packages("h2o", repos = "https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type = "source")
install.packages("gbmt")
install.packages("lime")
install.packages("lime")
Sys.setenv(VROOM_CONNECTION_SIZE = 131072 * 10)
# Load the 2024-2025 NBA game data
game_logs_2025 <- game_logs(seasons = 2025)
game_ids <- game_logs_2025 %>%
mutate(team = nameTeam,
game_id=idGame) %>%
group_by(game_id, team) %>%
summarise(
possessions = (sum(fga) - sum(oreb)) + sum(tov) + (0.436 * sum(fta)),
mins = sum(minutes) / 5,
ppg = sum(pts),
ppm = ppg / mins
) %>%
left_join(game_logs_2025, by = c("game_id"="idGame", "team"="nameTeam")) %>%
select(game_id, team, possessions, mins, ppg, ppm,numberGameTeamSeason)|>
group_by(team)|>
distinct()|>
ungroup()|>
group_by(game_id)%>%
mutate(  team_num = row_number())
# Filter for away team stats
game_stat_away <- game_ids %>%
filter(row_number() %% 2 == 1)|>
mutate(away_ppg=ppg,
away_posessions=possessions,
away_team=team,
away_game_no=numberGameTeamSeason)
# Filter for home team stats
game_stat_home <- game_ids %>%
filter(row_number() %% 2 == 0)|>
mutate(home_ppg=ppg,
home_posessions=possessions,
home_team=team,
home_game_no=numberGameTeamSeason)
game_stat_merge <- inner_join(game_stat_away, game_stat_home, by = "game_id") %>%
mutate(
away_OR = 100 * away_ppg / away_posessions,
home_OR = 100 * home_ppg / home_posessions,
away_DR = 100 * home_ppg / home_posessions,
home_DR = 100 * away_ppg / away_posessions,
away_possessions = away_posessions,
home_possessions = home_posessions
) %>%
pivot_longer(
cols = c(away_OR, home_OR, away_DR, home_DR,away_possessions, home_possessions),
names_to = c("team_type", "stat"),
names_sep = "_"
) %>%
mutate(
team = case_when(
team_type == "away" ~ away_team,
team_type == "home" ~ home_team
),
game_no = case_when(
team_type == "away" ~ away_game_no,
team_type == "home" ~ home_game_no
)
) %>%
pivot_wider(
id_cols = c(game_id, team, game_no),
names_from = stat,
values_from = value
)%>%
arrange(team, game_no) %>%
group_by(team) %>%
mutate(
OR_sum = lag(cumsum(OR)),
DR_sum = lag(cumsum(DR)),
possessions_sum = lag(cumsum(possessions)),
game_minus_1 = game_no - 1,
OR_ma = OR_sum / game_minus_1,
DR_ma = DR_sum / game_minus_1,
possessions_ma = possessions_sum / game_minus_1
) %>%
ungroup() %>%
group_by(game_id) %>%
mutate(
opp_OR = lead(OR),
opp_DR = lead(DR),
opp_possessions = lead(possessions),
opp_games_minus_1 = lead(game_minus_1)
) |>
select(game_id, team, OR, OR_ma, DR, DR_ma, possessions, possessions_ma, opp_possessions) %>%
ungroup() %>%
mutate(
league_avg_OR = mean(OR, na.rm = TRUE),
league_avg_possessions = mean(possessions, na.rm = TRUE))%>%
group_by(game_id)%>%
mutate(
row_num = row_number()
)|>
select(game_id,team,OR,OR_ma,DR, DR_ma,row_num,league_avg_OR,
possessions, possessions_ma, opp_possessions, row_num, league_avg_OR, league_avg_possessions )
# Split into away and home teams
away_game_stat <- game_stat_merge %>%
filter(row_number() %% 2 == 1) %>%
mutate(
away_OR = OR,
away_DR = DR,
away_OR_ma = OR_ma,
away_DR_ma = DR_ma,
away_possessions_ma=possessions_ma,
away_possessions=possessions
) %>%
select(game_id, team, away_OR, away_DR, away_OR_ma, away_DR_ma, league_avg_OR,away_possessions_ma,away_possessions,league_avg_possessions)
home_game_stat <- game_stat_merge %>%
filter(row_number() %% 2 == 0) %>%
mutate(
home_OR = OR,
home_DR = DR,
home_OR_ma = OR_ma,
home_DR_ma = DR_ma,
home_poss_ma=possessions_ma,
home_poss=possessions
) %>%
select(game_id, team, home_OR, home_DR, home_OR_ma, home_DR_ma, league_avg_OR,home_poss_ma,home_poss,league_avg_possessions )
# Merge away and home stats
merged_data <- inner_join(away_game_stat, home_game_stat, by = "game_id") %>%
mutate(
away_opp_adj_OR = away_OR + league_avg_OR.x - home_DR_ma,
away_opp_adj_DR = away_DR + league_avg_OR.x - home_OR_ma,
home_opp_adj_OR = home_OR + league_avg_OR.x - away_DR_ma,
home_opp_adj_DR = home_DR + league_avg_OR.x - away_OR_ma,
away_opp_adj_possessions = away_possessions + league_avg_possessions.x - home_poss_ma,
home_opp_adj_possessions = home_poss + league_avg_possessions.x - away_possessions_ma
) %>%
mutate(away_team=team.x,
home_team=team.y)|>
select(-team.x, -team.y)|>
pivot_longer(
cols = c(away_OR, home_OR, away_DR, home_DR),
names_to = c("team_type", "stat"),
names_sep = "_"
) %>%
mutate(
team = case_when(
team_type == "away" ~ away_team,
team_type == "home" ~ home_team
),
opp_adj_OR = case_when(
team_type == "away" ~ away_opp_adj_OR,
team_type == "home" ~ home_opp_adj_OR
),
opp_adj_DR = case_when(
team_type == "away" ~ away_opp_adj_DR,
team_type == "home" ~ home_opp_adj_DR
) ,
opp_adj_poss = case_when(
team_type == "away" ~ away_opp_adj_possessions,
team_type == "home" ~ home_opp_adj_possessions
)
) %>%
pivot_wider(
id_cols = c(game_id, team, opp_adj_OR,opp_adj_DR,opp_adj_poss ),
names_from = stat,
values_from = value
)|>
select(game_id, team, opp_adj_OR, opp_adj_DR,opp_adj_poss)|>
na.omit()
###################################################################
#score prediction check
# Get game IDs for a specific season (e.g., 2023-24)
game_ids2 <- game_logs(seasons = 2025)
# Extract relevant game information
game_data <- game_ids2 %>%
select(
idGame,
dateGame,
nameTeam,
pts,
numberGameTeamSeason
)|>
group_by(idGame, nameTeam,numberGameTeamSeason)|>
summarise(max_pts=sum(pts)
)
#merge
points_prediction_df<- game_data|>
left_join(merged_data, by = c("idGame"="game_id",
"nameTeam"="team"))%>%
ungroup() %>%
select(-idGame, -nameTeam)%>%
na.omit()
#team final average
merged_data_team<-merged_data|>
group_by(team)|>
summarise(
avg_opp_OR=mean(opp_adj_OR),
avg_opp_DR=mean(opp_adj_DR),
avg_opp_poss=mean(opp_adj_poss),
net_rating=avg_opp_OR-avg_opp_DR
)|>
mutate(team_name= str_sub(team, 1, 8))
#last 10 games
merged_data_team_last_10<-merged_data|>
left_join(game_data, by = c("game_id"="idGame",
"team"="nameTeam"))%>%
group_by(team,numberGameTeamSeason)|>
summarise(
avg_opp_OR=mean(opp_adj_OR),
avg_opp_DR=mean(opp_adj_DR),
avg_opp_poss=mean(opp_adj_poss),
net_rating=avg_opp_OR-avg_opp_DR
)|>
mutate(team_name= str_sub(team, 1, 8))%>%
group_by(team) %>%  # Group by team for ranking
mutate(game_rank = dense_rank(desc(numberGameTeamSeason))) %>%
filter(game_rank <= 10) %>%
ungroup()|>
group_by(team_name)|>
summarise(
avg_opp_OR=mean(avg_opp_OR),
avg_opp_DR=mean(avg_opp_DR),
avg_opp_poss=mean(avg_opp_poss),
net_rating=avg_opp_OR-avg_opp_DR
)
##############################################################################
#all season
ggplot(data = merged_data_team, aes(x = avg_opp_OR, y = avg_opp_DR, label = team_name)) +
geom_point() +
geom_text(hjust = 0, vjust = -1) +  # Adjust hjust and vjust for label positioning
geom_hline(yintercept = mean(merged_data_team$avg_opp_DR), linetype = "dashed") +
geom_vline(xintercept = mean(merged_data_team$avg_opp_OR), linetype = "dashed") +
theme_bw() +
labs(x = "avg_opp_OR",
y = "avg_opp_DR",
title = "avg_opp_OR & avg_opp_DR in 2024-2025",
subtitle = "Regular season and playoffs included") +
theme(plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))+
scale_y_reverse()  # This is the key addition
#last 10
ggplot(data = merged_data_team_last_10, aes(x = avg_opp_OR, y = avg_opp_DR, label = team_name)) +
geom_point() +
geom_text(hjust = 0, vjust = -1) +  # Adjust hjust and vjust for label positioning
geom_hline(yintercept = mean(merged_data_team_last_10$avg_opp_DR), linetype = "dashed") +
geom_vline(xintercept = mean(merged_data_team_last_10$avg_opp_OR), linetype = "dashed") +
theme_bw() +
labs(x = "avg_opp_OR",
y = "avg_opp_DR",
title = "avg_opp_OR & avg_opp_DR in 2024-2025",
subtitle = "Last 10 games") +
theme(plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))+
scale_y_reverse() +  # Keep the y-axis reversed
geom_abline(intercept = 0, slope = 1, linetype = 2, color = "red") # Dashed
#OR
geom_abline(intercept = 0, slope = 1, linetype = 3, color = "red") # Dotted
#OR
geom_abline(intercept = 0, slope = 1, linetype = 4, color = "red") # Dotdash
#OR
geom_abline(intercept = 0, slope = 1, linetype = 5, color = "red") # Longdash
#OR
geom_abline(intercept = 0, slope = 1, linetype = 6, color = "red") # Twodash
##############################################################################
#PACE merge
game_ids_sum<-game_ids|>
group_by(team)|>
summarise(avg_poss=mean(possessions),
avg_points=mean(ppg)
)
#merge
team_sum<- merged_data_team|>
left_join(game_ids_sum, by = c("team"))|>
select(team, avg_opp_OR, avg_opp_DR, avg_poss)
##################################################################################
#schedule
future_games <-NBA_Regular_Season_2024_25_2024_2025_Regular_Season_Schedule2|>
mutate(`Game Date` = as.Date(`Game Date`, format = "%a, %b %d, %Y")) |>
filter(as.Date(`Game Date`) >= today())
rm(list = ls())
library(e1071)
library("DMwR2")
library(VIM)
library(caTools)
library(class)
library(tidyverse)
library(nflfastR)
library(nflverse)
library(ggimage)
library(gt)
library(gtExtras)
library(splitstackshape)
library(nflverse)
install.packages("SPlit")
library(SPlit)
library(caret)
library("tidymodels")
library("MASSExtra")
library("randomForest")
library("dplyr")
library(dplyr)
library(stringr)
library(SPlit)
library("h2o")
library(rsample)      # data splitting
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(caret)        # an aggregator package for performing many machine learning models
install.packages("h2o", repos="https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type="source")
library(h2o)
library(tidymodels)
install.packages("gbm.auto")
install.packages("gbm2sas")
install.packages("gbmt")
library(gbm)
library(vtreat)
install.packages("lime")
library("lime")
library("pdp")
library("kernlab")     # SVM methodology
library("e1071")        # SVM methodology
library("ISLR")         # contains example data set "Khan"
library("RColorBrewer")
library(xgboost)
########################################
#######################################
#load data 2010-2022
#######################################
pbp_2010_2023 <- load_pbp(2022:2023)%>%  # Load data for 2022 and 2023 seasons
# Filtering in multiple steps for clarity
filter(season_type == "REG") %>%  # Filter for regular season games
filter(!is.na(epa)) %>%  # Filter for rows with non-missing epa values
filter(play_type != "no_play" & !is.na(play_type)) %>%  # Filter for valid play types
filter(qb_kneel == 0)%>%
filter(!is.na(drive_time_of_possession))
pbp_2010_2023 <- load_pbp(2023:2023)
TEST <- pbp_2010_2023 %>%
filter(season_type == "REG", !is.na(epa), play_type != "no_play" & !is.na(play_type), qb_kneel == 0, !is.na(drive_time_of_possession)) %>%
group_by(game_id) %>%
mutate(
score_change = coalesce(total_home_score - lag(total_home_score, default = first(total_home_score)), 0) +
coalesce(total_away_score - lag(total_away_score, default = first(total_away_score)), 0),
half_end = (qtr == 2 & game_seconds_remaining == 0),
game_end = (qtr == 4 & game_seconds_remaining == 0 & qtr != 5) | (qtr == 5 & game_seconds_remaining == 0)
) %>%
ungroup()
rm(list = ls())
library(tidyverse)
library(xgboost)
library(randomForest)
library(splines)
library(matrixcalc)
library(lme4)
library(nflfastR)
library(nflreadr)
library(nflplotR)
library(grid)
library(nnet)
library(gridExtra)
library(loo)
library(latex2exp)
library(RColorBrewer)
library(cowplot)
library(dials)
library(rlist)
library(gam)
library(ggnewscale)
library(ggnewscale)
library(abind)
library(reshape2)
library(gt)
library(webshot2)
library(e1071)
library("DMwR2")
library(VIM)
library(caTools)
library(class)
library(tidyverse)
library(nflfastR)
library(nflverse)
library(ggimage)
library(gt)
library(gtExtras)
library(splitstackshape)
library(nflverse)
library(SPlit)
library(caret)
library("tidymodels")
library("MASSExtra")
library("randomForest")
library("dplyr")
library(dplyr)
library(stringr)
library(SPlit)
library("h2o")
library(rsample)      # data splitting
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(caret)        # an aggregator package for performing many machine learning models
install.packages("h2o", repos="https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type="source")
library(h2o)
library(tidymodels)
library (gbm.auto)
library (gbm2sas)
library (gbmt)
library(gbm)
library(vtreat)
install.packages("lime")
library("lime")
library("pdp")
library("kernlab")     # SVM methodology
library("e1071")        # SVM methodology
library("ISLR")         # contains example data set "Khan"
library("RColorBrewer")
library(xgboost)
install.packages("h2o", repos = "https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type = "source")
install.packages("h2o", repos = "https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type = "source")
source("A0_header.R")
pbp_2010_2023 <- load_pbp(2023:2023)
rm(list = ls())
library(tidyverse)
library(xgboost)
library(randomForest)
library(splines)
library(matrixcalc)
library(lme4)
library(nflfastR)
library(nflreadr)
library(nflplotR)
library(grid)
library(nnet)
library(gridExtra)
library(loo)
library(latex2exp)
library(RColorBrewer)
library(cowplot)
library(dials)
library(rlist)
library(gam)
library(ggnewscale)
library(ggnewscale)
library(abind)
library(reshape2)
library(gt)
library(webshot2)
library(e1071)
library("DMwR2")
library(VIM)
library(caTools)
library(class)
library(tidyverse)
library(nflfastR)
library(nflverse)
library(ggimage)
library(gt)
library(gtExtras)
library(splitstackshape)
library(nflverse)
library(SPlit)
library(caret)
library("tidymodels")
library("MASSExtra")
library("randomForest")
library("dplyr")
library(dplyr)
library(stringr)
library(SPlit)
library("h2o")
library(rsample)      # data splitting
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(caret)        # an aggregator package for performing many machine learning models
install.packages("h2o", repos="https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type="source")
library(h2o)
library(tidymodels)
library (gbm.auto)
library (gbm2sas)
library (gbmt)
library(gbm)
library(vtreat)
install.packages("lime")
library("lime")
library("pdp")
library("kernlab")     # SVM methodology
library("e1071")        # SVM methodology
library("ISLR")         # contains example data set "Khan"
library("RColorBrewer")
library(xgboost)
# this should be the default u y do this R
options(scipen = 999999)
# options(scipen = 50)
output_folder = "./plots/"
theme_set(theme_bw())
theme_update(text = element_text(size=16))
theme_update(plot.title = element_text(hjust = 0.5))
theme_update(
text = element_text(size=20),
plot.title = element_text(hjust = 0.5),
axis.title = element_text(size=20),
axis.text = element_text(size=20),
legend.text = element_text(size=20),
legend.title = element_text(size=20)
)
options(pillar.sigfig=4)
install.packages("h2o", repos = "https://h2o-release.s3.amazonaws.com/h2o/rel-nightly/R/1.4.18/h2o.tar.gz", type = "source")
install.packages("lime")
pbp_2010_2023 <- load_pbp(2023:2023)
pbp_2010_2023 <- load_pbp(2023:2023)
